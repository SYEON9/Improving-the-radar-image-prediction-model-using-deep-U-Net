{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-18T03:37:19.328294Z","iopub.execute_input":"2021-11-18T03:37:19.328682Z","iopub.status.idle":"2021-11-18T03:38:49.17406Z","shell.execute_reply.started":"2021-11-18T03:37:19.328591Z","shell.execute_reply":"2021-11-18T03:38:49.173162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport zipfile\nimport glob\nimport torch\nimport matplotlib.pylab as plt\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, Conv3D, Conv2DTranspose, MaxPooling2D, BatchNormalization, concatenate, Input, ConvLSTM2D,LSTM, Reshape\nfrom tensorflow.keras import Model\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:17.568648Z","iopub.execute_input":"2021-11-19T16:15:17.569332Z","iopub.status.idle":"2021-11-19T16:15:17.574369Z","shell.execute_reply.started":"2021-11-19T16:15:17.569296Z","shell.execute_reply":"2021-11-19T16:15:17.573544Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#GPU 사용 가능 여부 확인\nfrom tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:21.679233Z","iopub.execute_input":"2021-11-19T16:15:21.679506Z","iopub.status.idle":"2021-11-19T16:15:21.691578Z","shell.execute_reply.started":"2021-11-19T16:15:21.679475Z","shell.execute_reply":"2021-11-19T16:15:21.690715Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tf.test.is_gpu_available()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:24.675670Z","iopub.execute_input":"2021-11-19T16:15:24.676281Z","iopub.status.idle":"2021-11-19T16:15:24.690000Z","shell.execute_reply.started":"2021-11-19T16:15:24.676240Z","shell.execute_reply":"2021-11-19T16:15:24.689159Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data load\ntrain_files = glob.glob('../input/radar-image/train/train/*.npy')\nlen(train_files)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:27.996589Z","iopub.execute_input":"2021-11-19T16:15:27.997153Z","iopub.status.idle":"2021-11-19T16:15:28.201190Z","shell.execute_reply.started":"2021-11-19T16:15:27.997115Z","shell.execute_reply":"2021-11-19T16:15:28.200321Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data check\ndata_1st = np.load(train_files[0])\ndata_1st.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:28.835636Z","iopub.execute_input":"2021-11-19T16:15:28.836319Z","iopub.status.idle":"2021-11-19T16:15:28.842961Z","shell.execute_reply.started":"2021-11-19T16:15:28.836282Z","shell.execute_reply":"2021-11-19T16:15:28.842175Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#train data visualization\n\n#color map setting\ncolor_map = plt.cm.get_cmap('RdBu')\ncolor_map = color_map.reversed()\n\n#visualization\nplt.style.use('fivethirtyeight')\nplt.figure(figsize = (20,20))\n\nfor i in range(4):\n    plt.subplot(1,5,i+1)\n    plt.imshow(data_1st[:,:,i],cmap = color_map)\n    \nplt.subplot(1,5,5)\nplt.imshow(data_1st[:,:,-1], cmap=color_map)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:29.574007Z","iopub.execute_input":"2021-11-19T16:15:29.574606Z","iopub.status.idle":"2021-11-19T16:15:30.165501Z","shell.execute_reply.started":"2021-11-19T16:15:29.574572Z","shell.execute_reply":"2021-11-19T16:15:30.164391Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data preprocessing\n\ndef trainGenerator():\n    for file in train_files:\n        dataset = np.load(file)\n        target = dataset[:,:,-1].reshape(120,120,1)\n        remove_minus = np.where(target<0,0,target)\n        feature = dataset[:,:,:4]\n        \n        yield (feature, remove_minus)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:30.566058Z","iopub.execute_input":"2021-11-19T16:15:30.566564Z","iopub.status.idle":"2021-11-19T16:15:30.571824Z","shell.execute_reply.started":"2021-11-19T16:15:30.566523Z","shell.execute_reply":"2021-11-19T16:15:30.570890Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_generator(trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([120,120,4]),tf.TensorShape([120,120,1])))\ntrain_dataset = train_dataset.batch(4).prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:32.457420Z","iopub.execute_input":"2021-11-19T16:15:32.457717Z","iopub.status.idle":"2021-11-19T16:15:32.485502Z","shell.execute_reply.started":"2021-11-19T16:15:32.457670Z","shell.execute_reply":"2021-11-19T16:15:32.484624Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, ZeroPadding2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers.merge import concatenate, add, average\nfrom keras.layers import LeakyReLU, BatchNormalization, Activation, Dropout, MaxPooling2D\nfrom keras import regularizers\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:34.113500Z","iopub.execute_input":"2021-11-19T16:15:34.113775Z","iopub.status.idle":"2021-11-19T16:15:34.119017Z","shell.execute_reply.started":"2021-11-19T16:15:34.113743Z","shell.execute_reply":"2021-11-19T16:15:34.118303Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#unet model\ndef deepUnet_model(input_layer, start_neurons):\n    \n    #unet 1layer\n    conv1 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    bn1 = BatchNormalization()(conv1)\n    conv1_2 = Conv2D(start_neurons * 1, (3, 3), activation='relu', padding = 'same')(bn1)\n    bn1_2 = BatchNormalization()(conv1_2)  #(120,120,32)\n    \n    #shortcut part  #(120,120,32)\n    shortcut1 = Conv2D(start_neurons *1 ,(1,1), activation='relu',padding='same')(input_layer)\n    \n    add1 = add([bn1_2, shortcut1]) #(120,120,64)\n    add1 = Activation(activation = 'relu')(add1)\n    pool1 = MaxPooling2D((2, 2))(add1)  #(60,60,64)\n\n    #encoder 2layer  (60,60,64)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    bn2 = BatchNormalization()(conv2)\n    conv2_2 = Conv2D(start_neurons * 1, (3, 3), activation='relu', padding = 'same')(bn2)\n    bn2_2 = BatchNormalization()(conv2_2)  #(60,60,32)\n    \n    #shortcut part  (60,60,32)\n    shortcut2 = Conv2D(start_neurons *1 ,(1,1), activation='relu',padding='same')(pool1)\n    \n    add2 = add([bn2_2, shortcut2])  #(60,60,64)\n    add2 = Activation(activation = 'relu')(add2)\n    pool2 = MaxPooling2D((2, 2))(add2)  #(30,30,64)\n\n    convm = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(add2)\n    #(30,30,64)\n    \n    #(60,60,64)\n    uconv2 = concatenate([convm, conv2])\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(deconv2)\n    uconv2 = BatchNormalization()(uconv2)\n\n    uconv1 = concatenate([uconv2, conv1])\n    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    \n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n   \n    return output_layer\n\n    \ninput_layer = Input((120, 120, 4))\noutput_layer = deepUnet_model(input_layer,32)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:36.391828Z","iopub.execute_input":"2021-11-19T16:15:36.392401Z","iopub.status.idle":"2021-11-19T16:15:36.563368Z","shell.execute_reply.started":"2021-11-19T16:15:36.392363Z","shell.execute_reply":"2021-11-19T16:15:36.562656Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"/device:GPU:0\"):\n    model = Model(input_layer, output_layer)\n    model.compile(loss='mae', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:38.478434Z","iopub.execute_input":"2021-11-19T16:15:38.479893Z","iopub.status.idle":"2021-11-19T16:15:38.495287Z","shell.execute_reply.started":"2021-11-19T16:15:38.479841Z","shell.execute_reply":"2021-11-19T16:15:38.494232Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:40.347174Z","iopub.execute_input":"2021-11-19T16:15:40.347679Z","iopub.status.idle":"2021-11-19T16:15:40.378267Z","shell.execute_reply.started":"2021-11-19T16:15:40.347631Z","shell.execute_reply":"2021-11-19T16:15:40.375778Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#gpu 사용하여 학습해보자\nwith tf.device(\"/device:GPU:0\"):\n    model.fit(train_dataset, epochs = 1, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:15:45.081241Z","iopub.execute_input":"2021-11-19T16:15:45.081527Z","iopub.status.idle":"2021-11-19T16:19:50.303602Z","shell.execute_reply.started":"2021-11-19T16:15:45.081496Z","shell.execute_reply":"2021-11-19T16:19:50.302833Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:20:00.675306Z","iopub.execute_input":"2021-11-19T16:20:00.675890Z","iopub.status.idle":"2021-11-19T16:20:00.680908Z","shell.execute_reply.started":"2021-11-19T16:20:00.675849Z","shell.execute_reply":"2021-11-19T16:20:00.680134Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#unet model\ndef unet_model(input_layer, start_neurons):\n    \n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    pool1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D((2, 2))(pool1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    pool2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D((2, 2))(pool2)\n\n    convm = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    \n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n   \n    return output_layer\n\n    \nin_layer = Input((120, 120, 4))\nout_layer = unet_model(in_layer,64)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:20:02.731617Z","iopub.execute_input":"2021-11-19T16:20:02.732145Z","iopub.status.idle":"2021-11-19T16:20:02.851999Z","shell.execute_reply.started":"2021-11-19T16:20:02.732106Z","shell.execute_reply":"2021-11-19T16:20:02.851319Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"/device:GPU:0\"):\n    model2 = Model(in_layer, out_layer)\n    model2.compile(loss='mae', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:20:04.734953Z","iopub.execute_input":"2021-11-19T16:20:04.735821Z","iopub.status.idle":"2021-11-19T16:20:04.750996Z","shell.execute_reply.started":"2021-11-19T16:20:04.735771Z","shell.execute_reply":"2021-11-19T16:20:04.750076Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:20:05.881647Z","iopub.execute_input":"2021-11-19T16:20:05.882364Z","iopub.status.idle":"2021-11-19T16:20:05.899246Z","shell.execute_reply.started":"2021-11-19T16:20:05.882326Z","shell.execute_reply":"2021-11-19T16:20:05.898432Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#gpu 사용하여 학습해보자\nwith tf.device(\"/device:GPU:0\"):\n    model2.fit(train_dataset, epochs = 1, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:20:07.974779Z","iopub.execute_input":"2021-11-19T16:20:07.975061Z","iopub.status.idle":"2021-11-19T16:24:30.581521Z","shell.execute_reply.started":"2021-11-19T16:20:07.975031Z","shell.execute_reply":"2021-11-19T16:24:30.580757Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DeepUNet():\n    def __init__(self):\n        print(\"build deepUNet ...\")\n        \n    def down_block(self, data, n_filter, name):\n        x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(data)\n        temp = Conv2D(filters=n_filter, kernel_size = (3,3), strides = (1,1), padding = 'same', name = 'conv_{}'.format(name))(x)\n        temp = Activation('relu')(temp)\n        bn = BatchNormalization()(temp)\n        \n        bn = self.shortcut(x, bn)\n        act = Activation('relu')(bn)\n        return bn, act\n    \n    def up_block(self, act, bn, n_filter, name):\n        x = UpSampling2D(size = (2,2), name = 'upsample_{}'.format(name))(act)\n        \n        temp = concatenate([bn, x], axis = 1)\n        temp = Conv2D(filters=n_filter, kernel_size = (3,3), strides = (1,1), padding = 'same', name = 'conv_{}'.format(name))(x)\n        temp = Activation('relu')(temp)\n        \n        bn = BatchNormalization()(temp)\n        bn = self.shortcut(x, bn)\n        act = Activation('relu')(bn)\n        \n        return act\n        \n    \n    def shortcut(self, input, residual):\n        \n        input_shape = K.int_shape(input)\n        \n        try:\n            residual_shape = np.shape(residual).as_list()\n        except:\n            residual_shape = np.shape(residual)\n        \n        \n        \n        #equal_width = input_shape[ROW_AXIS] == residual_shape[ROW_AXIS]\n        #equal_heights = input_shape[COL_AXIS] == residual_shape[COL_AXIS]\n        \n        stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n        stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n        equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n        \n        \n        shortcut = input\n        # 1 X 1 conv if shape is different. Else identity.\n        if stride_width > 1 or stride_height > 1 or not equal_channels:\n            \n            shortcut = Conv2D(filters = residual_shape[CHANNEL_AXIS],\n                             kernel_size = (1,1),\n                             strides = (stride_width, stride_height),\n                             padding = 'valid',\n                             kernel_initializer = 'he_normal',\n                             kernel_regularizer = regularizers.l2(0.0001))(input)\n        \n        return add([shortcut, residual])\n    \n    \n    \n    def handle_dim_ordering(self):\n        global ROW_AXIS\n        global COL_AXIS\n        global CHANNEL_AXIS\n        \n        ROW_AXIS = 1\n        COL_AXIS = 2\n        CHANNEL_AXIS = 3\n        \n    \n    \n    \n    def create_model(self, img_shape, n_filter):\n        \n        self.handle_dim_ordering()\n        K.set_learning_phase(True)\n        \n        inputs = Input(shape = img_shape)\n        \n        x = Conv2D(filters=n_filter, kernel_size = (3,3), strides = (1,1), padding = 'same', name = 'conv_{}'.format('conv0_1'))(inputs)\n        net = Conv2D(filters=n_filter, kernel_size = (3,3), strides = (1,1), padding = 'same', name = 'conv_{}'.format('conv0_2'))(x)\n        bn1 = BatchNormalization()(net)\n        act1 = Activation('relu')(bn1)  #(120,120,64)\n        \n        bn2, act2 = self.down_block(act1, 64, 'down2') #(60,60,32)\n        bn3, act3 = self.down_block(act2, 64, 'down3') #(30,30,32)\n        bn4, act4 = self.down_block(act3, 64, 'down4') #(15,15,32)\n        \n        temp = self.up_block(act4, bn3, 64, 'up4') #(30,30,32)\n        temp = self.up_block(temp, bn2, 64, 'up3') #(60,60,32)\n        temp = self.up_block(temp, bn1, 64, 'up2') #(120,120,64)\n        \n        output = Conv2D(1, (1,1), padding=\"same\", activation='relu')(temp) #(120,120,1)\n        \n        model = Model(outputs = output, inputs = inputs)\n        print(model.summary())\n        \n        return model","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:24:53.147779Z","iopub.execute_input":"2021-11-19T16:24:53.148087Z","iopub.status.idle":"2021-11-19T16:24:53.171349Z","shell.execute_reply.started":"2021-11-19T16:24:53.148055Z","shell.execute_reply":"2021-11-19T16:24:53.170669Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"/device:GPU:0\"):\n    model3 = DeepUNet().create_model((120, 120, 4),64)\n    model3.compile(loss='mae', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:25:00.077319Z","iopub.execute_input":"2021-11-19T16:25:00.077945Z","iopub.status.idle":"2021-11-19T16:25:00.291937Z","shell.execute_reply.started":"2021-11-19T16:25:00.077906Z","shell.execute_reply":"2021-11-19T16:25:00.291284Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#gpu 사용하여 학습해보자\nwith tf.device(\"/device:GPU:0\"):\n    model3.fit(train_dataset, epochs = 1, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:25:05.254724Z","iopub.execute_input":"2021-11-19T16:25:05.255572Z","iopub.status.idle":"2021-11-19T16:28:28.123652Z","shell.execute_reply.started":"2021-11-19T16:25:05.255532Z","shell.execute_reply":"2021-11-19T16:28:28.122911Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test 데이터 만들기\nimport random\n#test_files = random.sample(train_files, int(len(train_files)*0.3))\ntest_files = random.sample(train_files, 2674)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:28:53.593955Z","iopub.execute_input":"2021-11-19T16:28:53.594452Z","iopub.status.idle":"2021-11-19T16:28:53.601956Z","shell.execute_reply.started":"2021-11-19T16:28:53.594409Z","shell.execute_reply":"2021-11-19T16:28:53.600931Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"len(test_files)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:29:02.094238Z","iopub.execute_input":"2021-11-19T16:29:02.094506Z","iopub.status.idle":"2021-11-19T16:29:02.099895Z","shell.execute_reply.started":"2021-11-19T16:29:02.094470Z","shell.execute_reply":"2021-11-19T16:29:02.099226Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"x_test = []\nfor file in tqdm(test_files, desc = 'test'):\n    data = np.load(file)\n    feature = data[:,:,:4]\n    x_test.append(feature)\n    \nx_test = np.array(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:29:10.386857Z","iopub.execute_input":"2021-11-19T16:29:10.387609Z","iopub.status.idle":"2021-11-19T16:29:12.868246Z","shell.execute_reply.started":"2021-11-19T16:29:10.387553Z","shell.execute_reply":"2021-11-19T16:29:12.867474Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"y_test = []\nfor file in tqdm(test_files, desc = 'test'):\n    data = np.load(file)\n    target = data[:,:,-1].reshape(120,120,1)\n    remove_minus = np.where(target<0,0,target)\n    y_test.append(remove_minus)\n    \ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:29:17.279431Z","iopub.execute_input":"2021-11-19T16:29:17.279718Z","iopub.status.idle":"2021-11-19T16:29:19.671159Z","shell.execute_reply.started":"2021-11-19T16:29:17.279672Z","shell.execute_reply":"2021-11-19T16:29:19.670302Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#모델 성능 확인하기\npred1 = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:29:36.091473Z","iopub.execute_input":"2021-11-19T16:29:36.091762Z","iopub.status.idle":"2021-11-19T16:29:41.682307Z","shell.execute_reply.started":"2021-11-19T16:29:36.091725Z","shell.execute_reply":"2021-11-19T16:29:41.681504Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#모델 성능 확인하기\npred2 = model2.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:30:15.114825Z","iopub.execute_input":"2021-11-19T16:30:15.115117Z","iopub.status.idle":"2021-11-19T16:30:19.269439Z","shell.execute_reply.started":"2021-11-19T16:30:15.115085Z","shell.execute_reply":"2021-11-19T16:30:19.268653Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#모델 성능 확인하기\npred3 = model3.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:30:22.364917Z","iopub.execute_input":"2021-11-19T16:30:22.365459Z","iopub.status.idle":"2021-11-19T16:30:25.412313Z","shell.execute_reply.started":"2021-11-19T16:30:22.365414Z","shell.execute_reply":"2021-11-19T16:30:25.411429Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test data mae 측정\ndef MAE(y, pred):\n    return np.mean(np.abs(y-pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:30:30.809509Z","iopub.execute_input":"2021-11-19T16:30:30.809776Z","iopub.status.idle":"2021-11-19T16:30:30.814160Z","shell.execute_reply.started":"2021-11-19T16:30:30.809746Z","shell.execute_reply":"2021-11-19T16:30:30.813371Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"print(MAE(y_test, pred1))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:30:39.264306Z","iopub.execute_input":"2021-11-19T16:30:39.264566Z","iopub.status.idle":"2021-11-19T16:30:39.526226Z","shell.execute_reply.started":"2021-11-19T16:30:39.264537Z","shell.execute_reply":"2021-11-19T16:30:39.525404Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"print(MAE(y_test, pred2))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:30:48.461058Z","iopub.execute_input":"2021-11-19T16:30:48.461309Z","iopub.status.idle":"2021-11-19T16:30:48.695349Z","shell.execute_reply.started":"2021-11-19T16:30:48.461281Z","shell.execute_reply":"2021-11-19T16:30:48.694431Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print(MAE(y_test, pred3))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:30:54.246609Z","iopub.execute_input":"2021-11-19T16:30:54.247172Z","iopub.status.idle":"2021-11-19T16:30:54.387598Z","shell.execute_reply.started":"2021-11-19T16:30:54.247130Z","shell.execute_reply":"2021-11-19T16:30:54.386840Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#시각화\n#predict visualization\n\n#color map setting\ncolor_map = plt.cm.get_cmap('RdBu')\ncolor_map = color_map.reversed()\n\n#visualization\nplt.style.use('fivethirtyeight')\nplt.figure(figsize = (20,20))\n\nplt.subplot(1,5,1)\nplt.imshow(y_test[2], cmap = color_map)\nplt.subplot(1,5,2)\nplt.imshow(pred2[2], cmap=color_map)\nplt.subplot(1,5,3)\nplt.imshow(pred1[2], cmap = color_map)\nplt.subplot(1,5,4)\nplt.imshow(pred3[2], cmap=color_map)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:33:26.847969Z","iopub.execute_input":"2021-11-19T16:33:26.848840Z","iopub.status.idle":"2021-11-19T16:33:27.594184Z","shell.execute_reply.started":"2021-11-19T16:33:26.848786Z","shell.execute_reply":"2021-11-19T16:33:27.593535Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}