{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, ZeroPadding2D, Conv2DTranspose, UpSampling2D\nfrom keras.layers.merge import concatenate, add, average\nfrom keras.layers import LeakyReLU, BatchNormalization, Activation, Dropout, MaxPooling2D\nfrom keras import regularizers\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:52:57.102221Z","iopub.execute_input":"2021-11-23T13:52:57.102646Z","iopub.status.idle":"2021-11-23T13:53:03.354555Z","shell.execute_reply.started":"2021-11-23T13:52:57.102544Z","shell.execute_reply":"2021-11-23T13:53:03.353431Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport zipfile\nimport glob\nimport torch\nimport matplotlib.pylab as plt\nimport cv2\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, BatchNormalization, concatenate, Input\nfrom tensorflow.keras import Model\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:31.962532Z","iopub.execute_input":"2021-11-23T11:15:31.962993Z","iopub.status.idle":"2021-11-23T11:15:33.746673Z","shell.execute_reply.started":"2021-11-23T11:15:31.962953Z","shell.execute_reply":"2021-11-23T11:15:33.745962Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#GPU 사용 가능 여부 확인\nfrom tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:34.924083Z","iopub.execute_input":"2021-11-23T11:15:34.924634Z","iopub.status.idle":"2021-11-23T11:15:39.290016Z","shell.execute_reply.started":"2021-11-23T11:15:34.924594Z","shell.execute_reply":"2021-11-23T11:15:39.289007Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tf.test.is_gpu_available()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:43.444654Z","iopub.execute_input":"2021-11-23T11:15:43.444933Z","iopub.status.idle":"2021-11-23T11:15:43.456328Z","shell.execute_reply.started":"2021-11-23T11:15:43.444902Z","shell.execute_reply":"2021-11-23T11:15:43.455516Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data load\ntrain_files = glob.glob('../input/radar-image/train/train/*.npy')\nlen(train_files)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:48.842512Z","iopub.execute_input":"2021-11-23T11:15:48.843075Z","iopub.status.idle":"2021-11-23T11:15:50.787711Z","shell.execute_reply.started":"2021-11-23T11:15:48.843015Z","shell.execute_reply":"2021-11-23T11:15:50.786925Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#train, test 데이터 분할\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(train_files, test_size = 0.2, shuffle=True, random_state=1004)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:51.747665Z","iopub.execute_input":"2021-11-23T11:15:51.747914Z","iopub.status.idle":"2021-11-23T11:15:52.316979Z","shell.execute_reply.started":"2021-11-23T11:15:51.747886Z","shell.execute_reply":"2021-11-23T11:15:52.316264Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(len(test))\nprint(len(train))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:53.839503Z","iopub.execute_input":"2021-11-23T11:15:53.840010Z","iopub.status.idle":"2021-11-23T11:15:53.845389Z","shell.execute_reply.started":"2021-11-23T11:15:53.839970Z","shell.execute_reply":"2021-11-23T11:15:53.844333Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data preprocessing\n\ndef trainGenerator():\n    for file in train_files:\n        dataset = np.load(file)\n        target = dataset[:,:,-1].reshape(120,120,1)\n        remove_minus = np.where(target<0,0,target)\n        feature = dataset[:,:,:4]\n        \n        yield (feature, remove_minus)\n\ndef valGenerator():\n    for file in val_files:\n        dataset = np.load(file)\n        target= dataset[:,:,-1].reshape(120,120,1)        \n        remove_minus = np.where(target < 0, 0, target)\n        feature = dataset[:,:,:4]\n\n\n        yield (feature, remove_minus)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:56.344324Z","iopub.execute_input":"2021-11-23T11:15:56.344877Z","iopub.status.idle":"2021-11-23T11:15:56.355569Z","shell.execute_reply.started":"2021-11-23T11:15:56.344838Z","shell.execute_reply":"2021-11-23T11:15:56.354759Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#unet model\ndef deepUnet_model(input_layer, start_neurons):\n    \n    #unet 1layer\n    conv1 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    bn1 = BatchNormalization()(conv1)\n    conv1_2 = Conv2D(start_neurons * 1, (3, 3), activation='relu', padding = 'same')(bn1)\n    bn1_2 = BatchNormalization()(conv1_2)  #(120,120,32)\n    \n    #shortcut part  #(120,120,32)\n    shortcut1 = Conv2D(start_neurons *1 ,(1,1), activation='relu',padding='same')(input_layer)\n    \n    add1 = add([bn1_2, shortcut1]) #(120,120,64)\n    add1 = Activation(activation = 'relu')(add1)\n    pool1 = MaxPooling2D((2, 2))(add1)  #(60,60,64)\n\n    \n    \n    #encoder 2layer  (60,60,64)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    bn2 = BatchNormalization()(conv2)\n    conv2_2 = Conv2D(start_neurons * 1, (3, 3), activation='relu', padding = 'same')(bn2)\n    bn2_2 = BatchNormalization()(conv2_2)  #(60,60,32)\n    \n    #shortcut part  (60,60,32)\n    shortcut2 = Conv2D(start_neurons *1 ,(1,1), activation='relu',padding='same')(pool1)\n    \n    add2 = add([bn2_2, shortcut2])  #(60,60,64)\n    add2 = Activation(activation = 'relu')(add2)\n    pool2 = MaxPooling2D((2, 2))(add2)  #(30,30,64)\n\n    \n    \n    convm = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    convm = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    #(30,30,64)\n    #convm을 uppooling해서 처리\n    \n    \n    #decoder1\n    #(60,60,64)\n    uconv2 = concatenate([convm, conv2])\n    \n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    uconv2 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    #shortcut\n    shortcut_d2 = Conv2D(start_neurons *1 ,(1,1), activation='relu',padding='same')(uconv2)\n    #add\n    add_d2 = add([uconv2, shortcut_d2])\n    add_d2 = Activation(activation = 'relu')(add_d2)\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(add_d2)\n    \n\n   \n\n    #decoder2\n    uconv1 = concatenate([deconv2, conv1])\n    \n    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    #shortcut\n    shortcut_d1 = Conv2D(start_neurons *1 ,(1,1), activation='relu',padding='same')(uconv1)\n    #add\n    add_d1 = add([uconv1, shortcut_d1])\n    add_d1 = Activation(activation = 'relu')(add_d1)\n    #deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(add_d1)\n    \n    \n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(add_d1)\n   \n    return output_layer\n\n    \ninput_layer = Input((120, 120, 4))\noutput_layer = deepUnet_model(input_layer,32)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:57.167614Z","iopub.execute_input":"2021-11-23T11:15:57.167865Z","iopub.status.idle":"2021-11-23T11:15:57.743913Z","shell.execute_reply.started":"2021-11-23T11:15:57.167836Z","shell.execute_reply":"2021-11-23T11:15:57.743248Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"/device:GPU:0\"):\n    model3 = Model(input_layer, output_layer)\n    model3.compile(loss='mae', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:25:41.371452Z","iopub.execute_input":"2021-11-23T13:25:41.371721Z","iopub.status.idle":"2021-11-23T13:25:41.388593Z","shell.execute_reply.started":"2021-11-23T13:25:41.371691Z","shell.execute_reply":"2021-11-23T13:25:41.387744Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model3.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:25:42.226573Z","iopub.execute_input":"2021-11-23T13:25:42.226985Z","iopub.status.idle":"2021-11-23T13:25:42.253658Z","shell.execute_reply.started":"2021-11-23T13:25:42.226943Z","shell.execute_reply":"2021-11-23T13:25:42.252705Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#gpu 사용하여 학습해보자\nwith tf.device(\"/device:GPU:0\"):\n    model3.fit(train_dataset, epochs = 5, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:25:49.710870Z","iopub.execute_input":"2021-11-23T13:25:49.711156Z","iopub.status.idle":"2021-11-23T13:42:52.514227Z","shell.execute_reply.started":"2021-11-23T13:25:49.711124Z","shell.execute_reply":"2021-11-23T13:42:52.511442Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#모델 성능 확인하기\npred3 = model3.predict(x_test)\nprint(MAE(y_test, pred3))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:44:37.678456Z","iopub.execute_input":"2021-11-23T13:44:37.679443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = np.array(train)\n\nimport os\nroot_path = './'","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:15:59.748416Z","iopub.execute_input":"2021-11-23T11:15:59.749001Z","iopub.status.idle":"2021-11-23T11:15:59.770557Z","shell.execute_reply.started":"2021-11-23T11:15:59.748959Z","shell.execute_reply":"2021-11-23T11:15:59.769245Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#K-fold 해보기\nimport gc\nfrom sklearn.model_selection import KFold\n\nall_scores = []\nall_preds = []\nidx = 0\n\nkf = KFold(n_splits = 5, random_state = 42)\nwith tf.device(\"/device:GPU:0\"):\n    for fold, (t, v) in enumerate(kf.split(train)):\n        print(type(v))\n        train_files = train[t]\n        val_files = train[v]\n        \n        #데이터 전처리\n        train_dataset = tf.data.Dataset.from_generator(trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([120,120,4]),tf.TensorShape([120,120,1])))\n        train_dataset = train_dataset.batch(4).prefetch(1)\n        \n        val_dataset = tf.data.Dataset.from_generator(valGenerator, (tf.float32, tf.float32), (tf.TensorShape([120,120,4]),tf.TensorShape([120,120,1])))\n        val_dataset = val_dataset.batch(4).prefetch(1)\n        \n        \n        #데이터 정리\n        input_layer = Input((120,120,4))\n        output_layer = deepUnet_model(input_layer,32)\n        \n        \n        model = Model(input_layer, output_layer)\n        adam = tf.keras.optimizers.Adam()\n        model.compile(optimizer=adam, loss='mae')\n\n        \n        #epoch마다 callback함수 실행\n        #모델의 개선이 없을 경우 learning rate를 조절해 모델의 개선을 유도. \n        callbacks = tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss', factor=0.2, patience=2, verbose=0, mode='min',\n                min_delta=0.0001, cooldown=0, min_lr=0)\n\n        sv = tf.keras.callbacks.ModelCheckpoint(\n            os.path.join(root_path,f'{fold}-rain.h5'),\n            monitor='val_loss', verbose=0, save_best_only=True,\n            save_weights_only=True, mode='min', save_freq='epoch')\n        \n        #epoch수를 좀 키울 필요가 있을듯\n        #earlystopping  = EarlyStopping(monitor = 'val_loss', patience = 10)\n        \n        model.fit(train_dataset, epochs = 5, verbose=1, validation_data=val_dataset, callbacks=[callbacks, sv])\n\n        del model\n        gc.collect()\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-23T11:16:08.448871Z","iopub.execute_input":"2021-11-23T11:16:08.449150Z","iopub.status.idle":"2021-11-23T12:42:15.473398Z","shell.execute_reply.started":"2021-11-23T11:16:08.449120Z","shell.execute_reply":"2021-11-23T12:42:15.472604Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#학습된 모델 불러오기\ninput_layer = Input((120,120,4))\noutput_layer = deepUnet_model(input_layer,32)\nmodel = Model(input_layer, output_layer)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:42:30.745268Z","iopub.execute_input":"2021-11-23T12:42:30.745528Z","iopub.status.idle":"2021-11-23T12:42:30.952679Z","shell.execute_reply.started":"2021-11-23T12:42:30.745499Z","shell.execute_reply":"2021-11-23T12:42:30.952033Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#테스트 데이터 로드\nx_test = []\nfor file in tqdm(test, desc = 'test_x'):\n    data = np.load(file)\n    feature = data[:,:,:4]\n    x_test.append(feature)\n    \nx_test = np.array(x_test)\n\n\n\ny_test = []\nfor file in tqdm(test, desc = 'test_y'):\n    data = np.load(file)\n    target = data[:,:,-1].reshape(120,120,1)\n    remove_minus = np.where(target<0,0,target)\n    y_test.append(remove_minus)\n    \ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:42:33.184496Z","iopub.execute_input":"2021-11-23T12:42:33.184764Z","iopub.status.idle":"2021-11-23T12:44:32.595678Z","shell.execute_reply.started":"2021-11-23T12:42:33.184736Z","shell.execute_reply":"2021-11-23T12:44:32.594908Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits=5, random_state=42)\ntotal_val = []\ntotal_answer = []\ntest_preds = []\n\nfor fold, (train, val) in enumerate(kf.split(train)):\n\n    val_file = train_files[val]\n    \n    X_val = []\n    X_answers = []\n  \n    for file in tqdm(val_file, desc='val'):\n        data = np.load(file)\n        X_answer = data[:,:,-1]\n        X_input = data[:,:,:4]\n  \n        X_val.append(X_input)\n        X_answers.append(X_answer)\n    \n    X_val = np.array(X_val)\n    X_answers = np.array(X_answers)\n    model.load_weights(os.path.join(root_path,f'{fold}-rain.h5'))\n\n    val_pred = model.predict(X_val)\n    test_pred = model.predict(x_test)\n\n    #test_pred = test_pred.reshape(-1,14400)\n    #final_X_val = val_pred.reshape(-1,14400)\n    total_val.append(val_pred)\n    total_answer.append(X_answers)\n    test_preds.append(test_pred)\n  \n    del val_pred, X_val, X_answers\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:45:13.132511Z","iopub.execute_input":"2021-11-23T12:45:13.132801Z","iopub.status.idle":"2021-11-23T12:50:49.708631Z","shell.execute_reply.started":"2021-11-23T12:45:13.132773Z","shell.execute_reply":"2021-11-23T12:50:49.705892Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#test data mae 측정\ndef MAE(y, pred):\n    return np.mean(np.abs(y-pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:50:55.450361Z","iopub.execute_input":"2021-11-23T12:50:55.451110Z","iopub.status.idle":"2021-11-23T12:50:55.456250Z","shell.execute_reply.started":"2021-11-23T12:50:55.451056Z","shell.execute_reply":"2021-11-23T12:50:55.455327Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(MAE(y_test, test_preds[0]))\nprint(MAE(y_test, test_preds[1]))\nprint(MAE(y_test, test_preds[2]))\nprint(MAE(y_test, test_preds[3]))\n#print(MAE(y_test, test_preds[4]))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:51:02.690015Z","iopub.execute_input":"2021-11-23T12:51:02.690624Z","iopub.status.idle":"2021-11-23T12:51:05.498334Z","shell.execute_reply.started":"2021-11-23T12:51:02.690586Z","shell.execute_reply":"2021-11-23T12:51:05.497532Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#baseline model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_generator(trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([120,120,4]),tf.TensorShape([120,120,1])))\ntrain_dataset = train_dataset.batch(4).prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:57:28.279468Z","iopub.execute_input":"2021-11-23T12:57:28.280103Z","iopub.status.idle":"2021-11-23T12:57:28.306598Z","shell.execute_reply.started":"2021-11-23T12:57:28.280039Z","shell.execute_reply":"2021-11-23T12:57:28.305929Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#unet model\ndef unet_model(input_layer, start_neurons):\n    \n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    pool1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D((2, 2))(pool1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    pool2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D((2, 2))(pool2)\n\n    convm = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    \n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n   \n    return output_layer\n\n    \nin_layer = Input((120, 120, 4))\nout_layer = unet_model(in_layer,64)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:19:03.076339Z","iopub.execute_input":"2021-11-23T13:19:03.077246Z","iopub.status.idle":"2021-11-23T13:19:03.240177Z","shell.execute_reply.started":"2021-11-23T13:19:03.077205Z","shell.execute_reply":"2021-11-23T13:19:03.239446Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"with tf.device(\"/device:GPU:0\"):\n    model2 = Model(in_layer, out_layer)\n    model2.compile(loss='mae', optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:19:04.920436Z","iopub.execute_input":"2021-11-23T13:19:04.920989Z","iopub.status.idle":"2021-11-23T13:19:04.935113Z","shell.execute_reply.started":"2021-11-23T13:19:04.920950Z","shell.execute_reply":"2021-11-23T13:19:04.934435Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:19:05.925481Z","iopub.execute_input":"2021-11-23T13:19:05.926232Z","iopub.status.idle":"2021-11-23T13:19:05.944455Z","shell.execute_reply.started":"2021-11-23T13:19:05.926186Z","shell.execute_reply":"2021-11-23T13:19:05.943748Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#gpu 사용하여 학습해보자\nwith tf.device(\"/device:GPU:0\"):\n    model2.fit(train_dataset, epochs = 5, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T12:57:37.347460Z","iopub.execute_input":"2021-11-23T12:57:37.348011Z","iopub.status.idle":"2021-11-23T13:11:17.172867Z","shell.execute_reply.started":"2021-11-23T12:57:37.347972Z","shell.execute_reply":"2021-11-23T13:11:17.170966Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#모델 성능 확인하기\npred2 = model2.predict(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:11:52.289890Z","iopub.execute_input":"2021-11-23T13:11:52.291358Z","iopub.status.idle":"2021-11-23T13:12:05.940931Z","shell.execute_reply.started":"2021-11-23T13:11:52.291313Z","shell.execute_reply":"2021-11-23T13:12:05.940092Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(MAE(y_test, pred2))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:12:09.513182Z","iopub.execute_input":"2021-11-23T13:12:09.513466Z","iopub.status.idle":"2021-11-23T13:12:11.021295Z","shell.execute_reply.started":"2021-11-23T13:12:09.513436Z","shell.execute_reply":"2021-11-23T13:12:11.020383Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"pred1 = test_preds[2]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:12:27.035352Z","iopub.execute_input":"2021-11-23T13:12:27.036160Z","iopub.status.idle":"2021-11-23T13:12:27.040872Z","shell.execute_reply.started":"2021-11-23T13:12:27.036106Z","shell.execute_reply":"2021-11-23T13:12:27.040153Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#시각화\n#predict visualization\n\n#color map setting\ncolor_map = plt.cm.get_cmap('RdBu')\ncolor_map = color_map.reversed()\n\n#visualization\nplt.style.use('fivethirtyeight')\nplt.figure(figsize = (20,20))\n\nplt.subplot(1,5,1)\nplt.imshow(y_test[10], cmap = color_map)\nplt.subplot(1,5,2)\nplt.imshow(pred2[10], cmap=color_map)\nplt.subplot(1,5,3)\nplt.imshow(pred1[10], cmap = color_map)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T13:12:29.964449Z","iopub.execute_input":"2021-11-23T13:12:29.964999Z","iopub.status.idle":"2021-11-23T13:12:30.468491Z","shell.execute_reply.started":"2021-11-23T13:12:29.964958Z","shell.execute_reply":"2021-11-23T13:12:30.466809Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}